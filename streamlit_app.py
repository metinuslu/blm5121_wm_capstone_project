import os
import warnings

# import threading
# import time
# from datetime import datetime
# import pandas as pd

# import src.model as model
# import src.preprocess as preprocess
import streamlit as st
import streamlit.components.v1 as components
from dotenv import load_dotenv

from src.functions import download_dataset_from_kaggle
from src.streamlit_functions import (data_metadata, data_preview,
                                     data_profiling, data_profilingA)

from src.models.dt_algoritm import dt_train, dt_prediction, dt_model_chart, dt_model_evaluation, dt_save_model

# from st_pages import show_pages_from_config

warnings.filterwarnings("ignore")


def home():
    """Home Page of Streamlit UI"""

    st.title('Web Mining Project Title', anchor='top', help='Web Mining Project Help')
    st.header('Web Mining Project Header')
    st.subheader('Bu uygulama Web Mining (BLM-5121) Projesi kapsamƒ±nda ML Algoritmalarƒ± i√ßin geli≈ütirilmi≈ütir.')
    st.markdown('**1. Project Proposal:** Proje √∂nerisi ve proje hakkƒ±nda bilgi alabilirsiniz.')
    st.markdown('**2. Project System Design:** Proje a≈üamalarƒ± ve sistem tasarƒ±mƒ± hakkƒ±nda bilgi alabilirsiniz.')
    st.markdown('**3. Dataset Info:** Veri seti √∂nizlemesi yapabilirsiniz. Veri seti hakkƒ±nda bilgi alabilirsiniz.')
    st.markdown('**4. Multi Class Classification:** √áoklu sƒ±nƒ±flandƒ±rma uygulamasƒ±dƒ±r. Veri seti √ºzerinde √ßoklu sƒ±nƒ±flandƒ±rma yapabilirsiniz.')
    st.markdown('**5. Regression:** Regresyon uygulamasƒ±dƒ±r. Veri seti √ºzerinde regresyon analizi yapabilirsiniz.')
    st.markdown('**6. Clustering:** K√ºmeleme uygulamasƒ±dƒ±r. Veri seti √ºzerinde k√ºmeleme analizi yapabilirsiniz.')
    st.markdown('**7. App Info. & Credits:** Bu projede kullanƒ±lan Framework ve Libraryleri i√ßermektedir.')


def proposal():
    """Project Proposal Page"""

    with open(file="ProjectProposal.md", encoding="utf8") as p:
        st.markdown(p.read())


def pipeline():
    """Project System Design Page"""
    st.title('Project System Design Title')
    st.header('Project System Design Header')
    st.subheader('Proje Sistemi Tasarƒ±mƒ±: Proje a≈üamalarƒ± ve sistem tasarƒ±mƒ± hakkƒ±nda bilgi alabilirsiniz.')
    st.image(image="./pipeline/SystemDesign.jpg", 
             caption="Project System Design", 
             width=200, 
             use_column_width="auto"
             )


def data():
    """Dataset Information Page"""

    st.title('Dataset Information Title')
    st.header('Dataset Information Header')
    st.subheader('Veri seti √∂nizlemesi yapabilirsiniz. Veri seti hakkƒ±nda bilgi alabilirsiniz.')
    tab1, tab2, tab3, tab4 = st.tabs(["Meta Data", "Preview", "Profile(Raw Data)", "Profile(Preprocess Data)"])
    with tab1:
        st.image(image="https://storage.googleapis.com/kaggle-datasets-images/1732554/2832282/1be2ae7e0f1bc3983e65c76bfe3a436e/dataset-cover.jpg?t=2021-11-20-09-31-54",
                 caption="Body Performance Dataset from Kaggle",
                 width=200,
                 use_column_width="auto"
                 )
        st.title('Meta Data')
        st.header("Meta Data")
        data_metadata(file_path=DATA_FILE)
        # st.page_link(page="http://www.google.com", label="Dataset Url: Kaggle", icon="üåé")
    with tab2:
        st.title('Data Preview')
        st.header("Data Preview")
        data_preview(file_path=DATA_FILE)
    with tab3:
        st.title('Raw Data Profiling')
        st.header("Raw Data Profiling")
        with open(file="data/profiling/RawDataProfilingReport.html", encoding="utf8") as p:
            components.html(p.read(), height=4096, width=2160, scrolling=True)
    with tab4:
        st.title('Preprocess Data Profiling')
        st.header("Preprocess Data Profiling")
        with open(file="data/profiling/PreprocessDataProfilingReport.html", encoding="utf8") as p:
            components.html(p.read(), height=4096, width=2160, scrolling=True)


def classification():
    """Multi Class Classification Page"""

    st.title('Multi Class Classification Title')
    st.header('Multi Class Classification Algorithms Header')
    st.subheader('√áoklu sƒ±nƒ±flandƒ±rma uygulamasƒ±dƒ±r. Veri seti √ºzerinde √ßoklu sƒ±nƒ±flandƒ±rma yapabilirsiniz.')
    # option = st.selectbox("Multi Class Classification Alogritmalarƒ±?",
    #                       ("Decision Tree", "KNN", "LightGBM"),
    #                       index=None,
    #                       placeholder="Model se√ßiniz...",
    #                       )
    # st.write("Model Se√ßimi:", option)

    tab1, tab2, tab3, tab4 = st.tabs(["Decision Tree (DT)", "K Nearest Neighboor (KNN)", "Light GBM", "CatBoost"])
    with tab1:
        st.header("Decision Tree")
        st.write('Decision Tree i≈ülemi yapƒ±lacak.')

        tab1_1, tab1_2, tab1_3, tab1_4 = st.tabs(["Training Component Component", "Model Charts", "Prediction Component", "Other"])
        with tab1_1:
            st.header("Decision Tree Training Component")
            st.write('Decision Tree i≈ülemi yapƒ±lacak.')
            dt_train(df_test=None, target_column=None, model_name=None, model_params=None)

        with tab1_2:
            st.header("Decision Tree Model Charts")
            st.write('Decision Tree i≈ülemi yapƒ±lacak.')
            dt_model_chart(model_name=None, model_params=None, df_test=None, target_column=None)

        with tab1_3:
            st.header("Decision Tree Pre")
            st.write('Decision Tree i≈ülemi yapƒ±lacak.')
            dt_prediction(df_test=None, model_name=None, model_params=None)

        with tab1_4:
            st.header("Decision Tree Other")
            st.write('Decision Tree i≈ülemi yapƒ±lacak.')
            dt_model_evaluation(model_name=None, model_params=None, df_test=None, target_column=None)

    with tab2:
        st.header("K Nearest Neighboor")
        st.write('K Nearest Neighboor i≈ülemi yapƒ±lacak.')

        tab2_1, tab2_2, tab2_3 = st.tabs(["Training Component", "Model Charts", "Prediction Component"])
        with tab2_1:
            st.header("K Nearest Neighboor Training Component")
            st.write('K Nearest Neighboor i≈ülemi yapƒ±lacak.')
        with tab2_2:
            st.header("K Nearest Neighboor Model Charts")
            st.write('K Nearest Neighboor i≈ülemi yapƒ±lacak.')
        with tab2_3:
            st.header("K Nearest Neighboor Predection")
            st.write('K Nearest Neighboor i≈ülemi yapƒ±lacak.')

    with tab3:
        st.header("Light GBM")
        st.write('Light GBM i≈ülemi yapƒ±lacak.')

        tab3_1, tab3_2, tab3_3 = st.tabs(["Training Component", "Model Charts", "Prediction Component"])
        with tab3_1:
            st.header("Light GBM Training Component")
            st.write('Light GBM i≈ülemi yapƒ±lacak.')
        with tab3_2:
            st.header("Light GBM Model Charts")
            st.write('Light GBM i≈ülemi yapƒ±lacak.')
        with tab3_3:
            st.header("Light GBM Prediction Component")
            st.write('Light GBM i≈ülemi yapƒ±lacak.')

    with tab4:
        st.header("CatBoost")
        st.write('CatBoost i≈ülemi yapƒ±lacak.')

        tab4_1, tab4_2, tab4_3 = st.tabs(["Training Component", "Model Charts", "Prediction Component"])
        with tab4_1:
            st.header("CatBoost Training Component")
            st.write('CatBoost i≈ülemi yapƒ±lacak.')
        with tab4_2:
            st.header("CatBoost Model Charts")
            st.write('CatBoost i≈ülemi yapƒ±lacak.')
        with tab4_3:
            st.header("CatBoost Prediction Component")
            st.write('CatBoost i≈ülemi yapƒ±lacak.')


def regression():
    """Regression Page"""

    st.title('Regression Title')
    st.header('Regression Algorithms Header')
    st.subheader('Regresyon uygulamasƒ±dƒ±r. Veri seti √ºzerinde regresyon analizi yapabilirsiniz.')
    tab1, tab2, tab3 = st.tabs(["Training Component", "Model Charts", "Prediction Component"])

    with tab1:
        st.header("Training Component")
        st.write('Training Component i≈ülemi yapƒ±lacak.')

    with tab2:
        st.header("Model Charts")
        st.write('Model Charts i≈ülemi yapƒ±lacak.')
        tab2_1, tab2_2, tab2_3 = st.tabs(["Loss Model Charts", "Accuracy Model Charts", "Other Model Charts"])
        with tab2_1:
            st.image("https://static.streamlit.io/examples/dog.jpg", width=200)
        with tab2_2:
            st.image("https://static.streamlit.io/examples/dog.jpg", width=200)
        with tab2_3:
            st.image("https://static.streamlit.io/examples/dog.jpg", width=200)

    with tab3:
        st.header("Prediction Component")
        st.write('Prediction Component i≈ülemi yapƒ±lacak.')


def clustering():
    """Clustering Page"""

    st.title('Clustering Title')
    st.header('Clustering Algorithms Header')
    st.subheader('K√ºmeleme uygulamasƒ±dƒ±r. Veri seti √ºzerinde k√ºmeleme analizi yapabilirsiniz.')
    # st.write('1. Veri seti y√ºkleme')


def app_credits():
    """App Info. & Credits Page"""

    st.title('App Info. & Credits Title')
    st.header('App Info. & Credits Header')
    st.subheader('App Info. & Credits: Bu projede kullanƒ±lan Framework ve Libraryleri i√ßermektedir.')
    st.write('App Info. & Credits: Bu projede kullanƒ±lan Framework ve Libraryleri i√ßermektedir.')

    st.markdown('**Programming Language:** Python 3.12')
    st.markdown('**Libraries & Frameworks:** Pandas, Scikit-learn, Numpy, Matplotlib, Seaborn, Plotly')
    st.markdown('**UI:** Streamlit')
    st.markdown('**Dev. Tools:** Docker & Git')
    st.markdown('**Dash Url:** [StreamLit App](https://web-mining-project.streamlit.app/)')
    st.markdown('**Developed by:** Metin Uslu & Anƒ±l √ñzcan')
    # st.page_link(page="http://www.google.com", label="Google", icon="üåé")
    # st.page_link("your_app.py", label="Home", icon="üè†")
    # st.page_link("pages/page_1.py", label="Page 1", icon="1Ô∏è‚É£")
    # st.page_link("pages/page_2.py", label="Page 2", icon="2Ô∏è‚É£", disabled=True)


def menu(user_name=None, user_password=None):
    """Streamlit UI Menu
    Params:
        user_name: str 
        user_password: str
    """

    st.sidebar.title('Web Mining Project')
    menu = {
        'Giri≈ü': home,
        'Project Proposal': proposal,
        'Project System Design': pipeline,
        'Dataset Info': data,
        'Multi Class Classification Algorithms': classification,
        'Regression Algorithms': regression,
        'Clustering Algorithms': clustering,
        'App. Info. & Credits': app_credits
    }

    if st.session_state.get('login_success'):
        choice = st.sidebar.radio('Applications', list(menu.keys()))
        menu[choice]()
    else:
        with st.sidebar:
            with st.form(key='login_form'):
                st.title('Loging Page')
                username = st.text_input('User Name')
                password = st.text_input('Password', type='password')
                if st.form_submit_button('Login'):
                    if username == user_name and password == user_password:
                        st.session_state['login_success'] = True
                        st.success('Giri≈ü ba≈üarƒ±lƒ±, y√∂nlendiriliyorsunuz...')
                        st.experimental_rerun()
                    else:
                        st.error('Kullanƒ±cƒ± adƒ± veya ≈üifre yanlƒ±≈ü.')
                        st.session_state['login_success'] = False
    # show_pages_from_config()


if __name__ == "__main__":

    # Set Constants
    ROOT_PATH = os.getcwd()
    CFG_PATH = os.path.join(ROOT_PATH, 'cfg')
    # ENV_PATH = os.path.join(ROOT_PATH, '.env')
    ENV_FILE = os.path.join(CFG_PATH, '.env')
    DATA_PATH = os.path.join(ROOT_PATH, 'data')
    RAW_DATA_PATH = os.path.join(DATA_PATH, 'raw')
    PREPROCESSED_DATA_PATH = os.path.join(DATA_PATH, 'preprocessed')
    PROFILLING_PATH = os.path.join(DATA_PATH, 'profiling')

    DATA_FILE = os.path.join(RAW_DATA_PATH, 'bodyPerformance.csv')

    # Load Environment Variables
    load_dotenv(dotenv_path=ENV_FILE, encoding='utf-8', verbose=False)

    # Streamlit Secrets
    USER_NAME = os.environ.get("USER_NAME") if os.environ.get("USER_NAME") is not None else st.secrets["streamlit"]["USER_NAME"]
    USER_PASSWORD = os.environ.get("USER_PASSWORD") if os.environ.get("USER_PASSWORD") is not None else st.secrets["streamlit"]["USER_PASSWORD"]
    # print(USER_NAME, USER_PASSWORD)
    
    # Kaggle Secrets
    KAGGLE_USER_NAME = os.environ.get("KAGGLE_USER_NAME") if os.environ.get("KAGGLE_USER_NAME") is not None else st.secrets["kaggle"]["KAGGLE_USER_NAME"]
    KAGGLE_KEY = os.environ.get("KAGGLE_KEY") if os.environ.get("KAGGLE_KEY") is not None else st.secrets["kaggle"]["KAGGLE_KEY"]
    # print(KAGGLE_USER_NAME, KAGGLE_KEY)    

    st.set_page_config(
        page_title="Web Mining Project UI ",
        page_icon=":gem:",
        layout="wide",
        # layout="centered",        
        initial_sidebar_state="expanded",
        # initial_sidebar_state="auto",
        # menu_items=None,
        menu_items={'Get Help': 'https://www.extremelycoolapp.com/help',
                    'Report a bug': "https://www.extremelycoolapp.com/bug",
                    'About': "# This is a header. This is an *extremely* cool app!"
                    }
                    )

    # Download Dataset from Kaggle
    # download_dataset_from_kaggle(user_name="kukuroo3", dataset_name="body-performance-data", path=RAW_DATA_PATH)
    download_dataset_from_kaggle(kaggle_user_name=KAGGLE_USER_NAME, kaggle_key=KAGGLE_KEY, dataset_user_name="kukuroo3", dataset_name="body-performance-data", path=RAW_DATA_PATH)
    
    # Data Profiling
    # data_profiling(file_path=DATA_FILE, report_path=PROFILLING_PATH, minimal=False)
    data_profilingA(file_path=DATA_FILE, report_path=PROFILLING_PATH, minimal=False, report_file_name="RawDataProfilingReport")
    data_profilingA(file_path=DATA_FILE, report_path=PROFILLING_PATH, minimal=False, report_file_name="PreprocessDataProfilingReport")
    
    # Streamlit Menu
    menu(user_name=USER_NAME, user_password=USER_PASSWORD)